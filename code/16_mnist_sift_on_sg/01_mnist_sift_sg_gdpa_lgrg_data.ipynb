{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51acd900-d051-4d58-8099-d0534464dabc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.datasets import fetch_openml # to download mnist data\n",
    "import cv2 as cv\n",
    "\n",
    "# # add the path to my packages to system paths so they can be imported\n",
    "# import sys\n",
    "# sys.path.append('/home/yasamanparhizkar/Documents/yorku/01_thesis/code/my_packages')\n",
    "# # sys.path.append('F:\\MAScThesis\\code\\my_packages')\n",
    "# # sys.path.append('/home/yasamanparhizkar/Documents/thesis/code/my_packages')\n",
    "\n",
    "# import sift_on_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373047f9-0c53-4b68-8117-57b2c62bf7d1",
   "metadata": {},
   "source": [
    "# Setup the mnist-SIFT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af92a4a5-c29e-4ee6-a455-0c4d2981568c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = '../../data/fe_exp/mnist-org/'\n",
    "data_sz = 14780 # all available images on my personal computer right now\n",
    "img_sz = (28, 28)\n",
    "\n",
    "data_y = np.loadtxt(data_path+'lbls.txt')\n",
    "data_y = data_y[:data_sz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c45cd7d4-4373-410c-ad79-403773f7561a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_x = np.array([np.loadtxt(data_path+'fv_'+str(0)+'.txt')])\n",
    "for vect_i in range(1, data_sz):\n",
    "    data_x = np.append(data_x, [np.loadtxt(data_path+'fv_'+str(vect_i)+'.txt')], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de1961b1-aac0-4dbf-b438-510ca3c2166e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14780, 784)\n",
      "(14780,)\n"
     ]
    }
   ],
   "source": [
    "print(data_x.shape)\n",
    "print(data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eee421e3-7b9d-4b10-bf08-8891d8c41b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert train and validation images from 1D to 2D with 3 channels of [0,255] pixel values\n",
    "data_x_sift = ((data_x.reshape((data_x.shape[0], img_sz[0], img_sz[1], 1)))*256).astype('uint8')\n",
    "data_x_sift = np.broadcast_to(data_x_sift, (data_x.shape[0], img_sz[0], img_sz[1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b734ce2-fa2e-45a7-84dd-031c0fceec32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SIFT default parameter values are:\n",
    "nfeatures = 0\n",
    "nOctaveLayers = 3\n",
    "contrastThreshold = 0.04\n",
    "edgeThreshold = 10\n",
    "sigma = 1.6\n",
    "\n",
    "sift = cv.SIFT_create(nfeatures, nOctaveLayers, contrastThreshold, edgeThreshold, sigma)\n",
    "\n",
    "# extract SIFT descriptors for all training and validation images\n",
    "gray = np.array([cv.cvtColor(data_x_sift[0],cv.COLOR_BGR2GRAY)])\n",
    "for i in range(1, data_x_sift.shape[0]):\n",
    "    gray = np.append(gray, [cv.cvtColor(data_x_sift[i],cv.COLOR_BGR2GRAY)], axis=0)\n",
    "kp = []\n",
    "des = []\n",
    "for i in range(gray.shape[0]):\n",
    "    _kp, _des = sift.detectAndCompute(gray[i],None)\n",
    "    kp.append(_kp)\n",
    "    des.append(_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "818c466f-737c-4726-903b-8f43a75da224",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# discard all images that have less than 2 keypoints\n",
    "num_keypoints = [len(kp[i]) for i in range(len(kp))]\n",
    "to_discard_ind = [i for i in range(len(num_keypoints)) if (num_keypoints[i]==0 or num_keypoints[i]==1)]\n",
    "x_sift_mod = np.delete(data_x_sift, to_discard_ind, axis=0)\n",
    "y_mod = np.delete(data_y, to_discard_ind, axis=0)\n",
    "gray_mod = np.delete(gray, to_discard_ind, axis=0)\n",
    "kp_mod = [kp[i] for i in range(len(kp)) if i not in to_discard_ind]\n",
    "des_mod = [des[i] for i in range(len(des)) if i not in to_discard_ind]\n",
    "\n",
    "# find new number of train & val images\n",
    "data_sz_mod = data_sz - len(to_discard_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2570c8e9-b1e3-49f8-a44a-cd0778a42141",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select only two keypoints in all images with more than 2 keypoints\n",
    "for i in range(len(kp_mod)): # for each training or validation image\n",
    "    # calculate keypoint's distance from the top-left and bottom-right corners\n",
    "    left_dists = [(kp_mod[i][j], np.sum(np.array(kp_mod[i][j].pt)**2), des_mod[i][j]) for j in range(len(kp_mod[i]))]\n",
    "    right_dists = [(kp_mod[i][j], np.sum(np.array([img_sz[0]-kp_mod[i][j].pt[0], img_sz[1]-kp_mod[i][j].pt[1]])**2), \\\n",
    "                    des_mod[i][j]) for j in range(len(kp_mod[i]))]\n",
    "\n",
    "    # select closest keypoints to the top-left and bottom-right corners, discard all other keypoints\n",
    "    kp_mod[i] = (min(left_dists, key=lambda x:x[1])[0], min(right_dists, key=lambda x:x[1])[0])\n",
    "    des_mod[i] = np.array([min(left_dists, key=lambda x:x[1])[2], min(right_dists, key=lambda x:x[1])[2]])\n",
    "\n",
    "    # concatenate two descriptors\n",
    "    des_mod[i] = des_mod[i].reshape(-1)\n",
    "des_mod = np.array(des_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9ffb644-66d2-4659-a774-b7a17d1b467d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalize descriptors by method 2: double normalization\n",
    "# step 1 - feature-wise: subtract mean and divide by standard deviation of each feature.\n",
    "des_mod_nrm = des_mod.copy()\n",
    "des_mod_mean = np.mean(des_mod_nrm, axis=0, keepdims=True)\n",
    "des_mod_std = np.std(des_mod_nrm, axis=0, keepdims=True)\n",
    "des_mod_nrm = des_mod_nrm - des_mod_mean\n",
    "des_mod_nrm = des_mod_nrm / (des_mod_std + 0.01)\n",
    "# step 2 - smaple-wise: normalize l2-norm of each vector to 1.\n",
    "des_mod_norm = np.linalg.norm(des_mod_nrm, axis=1, keepdims=True)\n",
    "des_mod_nrm = des_mod_nrm / (des_mod_norm + 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae325ee2-591e-4a07-8605-1d3dc2d5ad90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_path = '../../data/fe_exp/mnist-sift/'\n",
    "for vect_i in range(data_sz_mod):\n",
    "    np.savetxt(save_path+'fv_'+str(vect_i)+'.csv', des_mod_nrm[vect_i])\n",
    "    \n",
    "np.savetxt(save_path+'lbls.csv', y_mod*2-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6183456d-3e9f-4287-8778-4bb86db3e8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
